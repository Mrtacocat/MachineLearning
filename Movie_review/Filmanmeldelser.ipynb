{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T11:43:00.494658800Z",
     "start_time": "2024-04-11T11:42:56.925080300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nøyaktighet: 0.83\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Opprett en liste av anmeldelser og deres kategorier\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle datasettet\n",
    "np.random.shuffle(documents)\n",
    "\n",
    "# Konverter data til en Pandas DataFrame\n",
    "df = pd.DataFrame(documents, columns=['words', 'category'])\n",
    "\n",
    "# Konverter ordene til setninger (str)\n",
    "df['words'] = df['words'].apply(' '.join)\n",
    "\n",
    "# Del datasettet inn i trenings- og testsett\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['words'], df['category'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Bruk CountVectorizer for å konvertere teksten til vektorer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Opprett en Naive Bayes modell\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Tren modellen på treningsdata\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Prediker på testdata\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "\n",
    "# Beregn nøyaktighet\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Nøyaktighet:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T11:42:54.486160300Z",
     "start_time": "2024-04-11T11:42:54.471634500Z"
    }
   },
   "id": "6304fb48710edad5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Learning Accuracy: 0.7833333333333333\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['neg' 'pos'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m    106\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 107\u001B[1;33m                 \u001B[0munique_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munion1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    108\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36munion1d\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001B[0m in \u001B[0;36munion1d\u001B[1;34m(ar1, ar2)\u001B[0m\n\u001B[0;32m    748\u001B[0m     \"\"\"\n\u001B[1;32m--> 749\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mar1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mar2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    750\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36munique\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001B[0m in \u001B[0;36munique\u001B[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001B[0m\n\u001B[0;32m    260\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0maxis\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 261\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_unique1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mar\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_inverse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_counts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    262\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_unpack_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mret\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001B[0m in \u001B[0;36m_unique1d\u001B[1;34m(ar, return_index, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m    321\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m         \u001B[0mar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m         \u001B[0maux\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mar\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-fcaba87e2188>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;31m# Evaluate unsupervised learning using accuracy (since we know the true labels)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 55\u001B[1;33m \u001B[0munsupervised_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclusters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     56\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Unsupervised Learning Accuracy:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munsupervised_accuracy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m     \u001B[1;31m# Compute accuracy for each possible representation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m     \u001B[0my_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'multilabel'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\MachineLearning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m    117\u001B[0m                     \u001B[1;34mf\"predictions provided by the classifier coincides with \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m                     \u001B[1;34mf\"the true labels.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m                 ) from e\n\u001B[0m\u001B[0;32m    120\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munique_values\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m                 \u001B[0my_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"multiclass\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['neg' 'pos'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download NLTK's movie_reviews corpus\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Load movie_reviews data\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle dataset\n",
    "np.random.shuffle(documents)\n",
    "\n",
    "# Convert data to a Pandas DataFrame\n",
    "df = pd.DataFrame(documents, columns=['words', 'category'])\n",
    "\n",
    "# Convert words to sentences (str)\n",
    "df['words'] = df['words'].apply(' '.join)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['words'], df['category'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessing: Use CountVectorizer to convert text to vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Supervised Learning: Create and train a Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "\n",
    "# Evaluate supervised learning model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Supervised Learning Accuracy:\", accuracy)\n",
    "\n",
    "# Unsupervised Learning: Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=2)  # Assuming 2 clusters for positive and negative\n",
    "kmeans.fit(X_train_vec)\n",
    "\n",
    "# Predict clusters on test data\n",
    "clusters = kmeans.predict(X_test_vec)\n",
    "\n",
    "# Evaluate unsupervised learning using accuracy (since we know the true labels)\n",
    "unsupervised_accuracy = metrics.accuracy_score(y_test, clusters)\n",
    "print(\"Unsupervised Learning Accuracy:\", unsupervised_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T09:53:34.539010700Z",
     "start_time": "2024-04-15T09:53:16.593557800Z"
    }
   },
   "id": "cfd1da3493bb2915",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Learning Accuracy: 0.845\n",
      "Unsupervised Learning Accuracy: 0.445\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download NLTK's movie_reviews corpus\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Load movie_reviews data\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle dataset\n",
    "np.random.shuffle(documents)\n",
    "\n",
    "# Convert data to a Pandas DataFrame\n",
    "df = pd.DataFrame(documents, columns=['words', 'category'])\n",
    "\n",
    "# Convert words to sentences (str)\n",
    "df['words'] = df['words'].apply(' '.join)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['words'], df['category'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessing: Use CountVectorizer to convert text to vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Supervised Learning: Create and train a Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = nb_classifier.predict(X_test_vec)\n",
    "\n",
    "# Evaluate supervised learning model\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Supervised Learning Accuracy:\", accuracy)\n",
    "\n",
    "# Unsupervised Learning: Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=2)  # Assuming 2 clusters for positive and negative\n",
    "kmeans.fit(X_train_vec)\n",
    "\n",
    "# Predict clusters on test data\n",
    "clusters = kmeans.predict(X_test_vec)\n",
    "\n",
    "# Convert cluster labels to match 'neg' and 'pos' labels\n",
    "# Here, we assume the majority label in each cluster represents the cluster\n",
    "cluster_labels = {0: 'neg', 1: 'pos'}  # Mapping of cluster label to 'neg' or 'pos'\n",
    "clusters_mapped = [cluster_labels[cluster] for cluster in clusters]\n",
    "\n",
    "# Evaluate unsupervised learning using accuracy (since we know the true labels)\n",
    "unsupervised_accuracy = metrics.accuracy_score(y_test, clusters_mapped)\n",
    "print(\"Unsupervised Learning Accuracy:\", unsupervised_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T09:54:38.847618800Z",
     "start_time": "2024-04-15T09:54:25.308685200Z"
    }
   },
   "id": "3ecf2ce05f189088",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45afdd0bdbac03a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
